{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6 Testing your code\n",
    "\n",
    "Everyone need to test their code. The easiest way is to do **manual testing**. All you need to do is make a list of all the features your application has, the different types of input it can accept, and the expected results. Now, every time you make a change to your code, you need to go through every single item on that list and check it.\n",
    "\n",
    "This is just time-consuming, to avoid this, we need **Automated testing**, which is the execution of your test plan (the parts of your application you want to test, the order in which you want to test them, and the expected responses) by a script instead of a human. Python already comes with a set of tools and libraries to help you create automated tests for your application. We’ll explore those tools and libraries in this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 Unit Tests vs. Integration Tests\n",
    "\n",
    "What is the Unit Test?\n",
    "\n",
    "Unit Tests are conducted by developers and test the unit of code( aka module, component) he or she developed. It is a testing method by which individual units of source code are tested to determine if they are ready to use. It helps to reduce the cost of bug fixes since the bugs are identified during the early phases of the development lifecycle.\n",
    "\n",
    "What is Integration Test?\n",
    "Integration testing is executed by testers and tests integration between software modules. It is a software testing technique where individual units of a program are combined and tested as a group. Test stubs and test drivers are used to assist in Integration Testing. Integration test is performed in two way, they are a bottom-up method and the top-down method.\n",
    "\n",
    "\n",
    "KEY DIFFERENCE\n",
    "- Unit testing is a testing method by which individual units of source code are tested to determine if they are ready to use, whereas Integration testing checks integration between software modules.\n",
    "- Unit Testing test each part of the program and shows that the individual parts are correct, whereas Integration Testing combines different modules in the application and test as a group to see they are working fine.\n",
    "- Unit Testing starts with the module specification, while Integration Testing starts with interface specification.\n",
    "- Unit Testing can be performed at any time, on the other hand, Integration Testing is performed after unit testing and before system testing.\n",
    "- Unit Testing is executed by the developer, whereas Integration Testing is performed by the testing team.\n",
    "- Unit Testing errors, can be found easily, whereas Integration Testing it is difficult to find errors.\n",
    "- Unit Testing is a kind of white box testing, whereas Integration Testing is a kind of black-box testing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 Choosing a testing framework\n",
    "\n",
    "There are many test framework (and runners) available for Python.\n",
    "- unittest : python default since version 2.1.\n",
    "- pytest : Most popular\n",
    "- nose or nose2 : test runner over unittest test case offers more options for filtering the tests that you execute\n",
    "\n",
    "\n",
    "In this chapter, we will learn pytest only, because **the code in pytest is simple, compact, and efficient**.\n",
    "\n",
    "For unittest, we will have to import modules, create a class and define the testing functions within that class. But for pytest, we only have to define the testing function. Pytest is also fast and efficient."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.3 First example\n",
    "\n",
    "To use pytest, you need to install it on your env `pip install pytest`\n",
    "\n",
    "You can find our first **unit test** example in `src/test_demo`. We have a function called my_sum in module MySum.py. It can calculate the sum of all element in a given Collection of int.\n",
    "\n",
    "```python\n",
    "from typing import Collection\n",
    "\n",
    "\n",
    "def my_sum(in_list: Collection[int]) -> int:\n",
    "    result = 0\n",
    "    for num in in_list:\n",
    "        result += num\n",
    "    return result\n",
    "```\n",
    "\n",
    "Then create a test file to store your tests. Note the pytest convention requires the test file should be **test_<module_name>**. In our case, the file called test_MySum.py.\n",
    "\n",
    "It contains below test case:\n",
    "```python\n",
    "from learning_python.Lesson01_Basics.Section01_Basic_syntax.src.test_demo.MySum import my_sum\n",
    "\n",
    "\n",
    "def test_my_sum_of_list():\n",
    "    assert my_sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "\n",
    "def test_my_sum_of_tuple():\n",
    "    assert my_sum((1, 2, 2)) == 5, \"Should be 5\"\n",
    "\n",
    "\n",
    "def test_my_sum_of_set():\n",
    "    assert my_sum({1, 2, 3}) == 6, \"should be 6\"\n",
    "```\n",
    "\n",
    "The naming convention of the test function should be **test_<function_name_to_be_tested>_<test_case_description>**. In above example, we test my_sum with list, tuple, and set as input.\n",
    "\n",
    "To run the tests, you need to go to the folder where your test files locate, and run command **pytest**. You should see below output\n",
    "\n",
    "```text\n",
    "(learning-python-41BW0Zzr-py3.8) pliu@ubuntu:~/git/Learning_Python/learning_python/Lesson01_Basics/Section01_Basic_syntax/src$ pytest\n",
    "===================================================================================================== test session starts =====================================================================================================\n",
    "platform linux -- Python 3.8.10, pytest-5.4.3, py-1.11.0, pluggy-0.13.1\n",
    "rootdir: /home/pliu/git/Learning_Python/learning_python/Lesson01_Basics/Section01_Basic_syntax/src\n",
    "collected 3 items\n",
    "\n",
    "test_demo/test_MySum.py ...                                                                                                                                                                                             [100%]\n",
    "\n",
    "====================================================================================================== 3 passed in 0.02s ======================================================================================================\n",
    "```\n",
    "\n",
    "Try to add another test case as below and rerun the test.\n",
    "\n",
    "```python\n",
    "def test_my_sum_wrong():\n",
    "    assert my_sum([1, 2, 3]) == 5, \"should be 6\"\n",
    "```\n",
    "\n",
    "You should see below output.\n",
    "\n",
    "```text\n",
    "test_MySum.py::test_my_sum_wrong FAILED                                  [100%]\n",
    "test_MySum.py:15 (test_my_sum_wrong)\n",
    "6 != 5\n",
    "\n",
    "Expected :5\n",
    "Actual   :6\n",
    "<Click to see difference>\n",
    "```\n",
    "\n",
    "So test framework notifies you when a test failed. You will have information on why it's failed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.4 The Arrange-Act-Assert model\n",
    "\n",
    "Most functional tests follow the Arrange-Act-Assert model:\n",
    "- Arrange, or set up, the conditions for the test\n",
    "- Act by calling some function or method\n",
    "- Assert that some end condition is true\n",
    "\n",
    "Testing frameworks typically hook into your test’s assertions so that they can provide information when an assertion fails.\n",
    "\n",
    "Let's retake the above example, and make it more clear\n",
    "\n",
    "```python\n",
    "def test_my_sum_explain():\n",
    "    # arrange: set up test conditions\n",
    "    expected_value = 6\n",
    "    input_param = [1, 2, 3]\n",
    "    # act: call the function that need to be tested\n",
    "    actual_value = my_sum(input_param)\n",
    "    # assert: check if the function returns the expected value\n",
    "    assert expected_value == actual_value\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.5 Fixtures: State and Dependency Management\n",
    "\n",
    "Your tests will often depend on pieces of data or test doubles for some of the objects in your code. In unittest, you might extract these dependencies into setUp() and tearDown() methods so each test in the class can make use of them. But in doing so, you may inadvertently make the test’s dependence on a particular piece of data or object entirely **implicit**.\n",
    "\n",
    "pytest takes a different approach. It leads you toward explicit dependency declarations that are still reusable thanks to the availability of **fixtures**. pytest fixtures are functions that create data or test doubles or initialize some system state for the test suite. **Any test that wants to use a fixture must explicitly accept it as an argument, so dependencies are always stated up front**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.5.1 When to use fixtures\n",
    "\n",
    "**If you have many test cases that uses the same data or state, you should use fixtures to avoid duplicating code for data or state initialization.**\n",
    "\n",
    "Imagine you’re writing a function, format_data_for_display(), to process the data returned by an API endpoint. The data represents a list of people, each with a given name, family name, and job title. The function should output a list of strings that include each person’s full name (their given_name followed by their family_name), a colon, and their title. To test this, you might write the following code:\n",
    "\n",
    "```python\n",
    "def format_data_for_display(people):\n",
    "    ...  # Implement this!\n",
    "\n",
    "def test_format_data_for_display():\n",
    "    people = [\n",
    "        {\n",
    "            \"given_name\": \"Alfonsa\",\n",
    "            \"family_name\": \"Ruiz\",\n",
    "            \"title\": \"Senior Software Engineer\",\n",
    "        },\n",
    "        {\n",
    "            \"given_name\": \"Sayid\",\n",
    "            \"family_name\": \"Khan\",\n",
    "            \"title\": \"Project Manager\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    assert format_data_for_display(people) == [\n",
    "        \"Alfonsa Ruiz: Senior Software Engineer\",\n",
    "        \"Sayid Khan: Project Manager\",\n",
    "    ]\n",
    "```\n",
    "\n",
    "Now suppose you need to write another function to transform the data into comma-separated values for use in Excel. The test would look awfully similar:\n",
    "\n",
    "```python\n",
    "def format_data_for_excel(people):\n",
    "    ... # Implement this!\n",
    "\n",
    "def test_format_data_for_excel():\n",
    "    people = [\n",
    "        {\n",
    "            \"given_name\": \"Alfonsa\",\n",
    "            \"family_name\": \"Ruiz\",\n",
    "            \"title\": \"Senior Software Engineer\",\n",
    "        },\n",
    "        {\n",
    "            \"given_name\": \"Sayid\",\n",
    "            \"family_name\": \"Khan\",\n",
    "            \"title\": \"Project Manager\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    assert format_data_for_excel(people) == \"\"\"given,family,title\n",
    "Alfonsa,Ruiz,Senior Software Engineer\n",
    "Sayid,Khan,Project Manager\n",
    "\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "If you use fixtures, you can group the repeated data initialization into a single function decorated with **@pytest.fixture** to indicate that the function is a pytest fixture:\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def example_people_data():\n",
    "    return [\n",
    "        {\n",
    "            \"given_name\": \"Alfonsa\",\n",
    "            \"family_name\": \"Ruiz\",\n",
    "            \"title\": \"Senior Software Engineer\",\n",
    "        },\n",
    "        {\n",
    "            \"given_name\": \"Sayid\",\n",
    "            \"family_name\": \"Khan\",\n",
    "            \"title\": \"Project Manager\",\n",
    "        },\n",
    "    ]\n",
    "```\n",
    "\n",
    "You can use the fixture by adding it as an argument to your tests. Its value will be the return value of the fixture function:\n",
    "\n",
    "```python\n",
    "def test_format_data_for_display(example_people_data):\n",
    "    assert format_data_for_display(example_people_data) == [\n",
    "        \"Alfonsa Ruiz: Senior Software Engineer\",\n",
    "        \"Sayid Khan: Project Manager\",\n",
    "    ]\n",
    "\n",
    "def test_format_data_for_excel(example_people_data):\n",
    "    assert format_data_for_excel(example_people_data) == \"\"\"given,family,title\n",
    "Alfonsa,Ruiz,Senior Software Engineer\n",
    "Sayid,Khan,Project Manager\n",
    "\"\"\"\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5.2 When to Avoid Fixtures\n",
    "\n",
    "Fixtures are great for extracting data or objects that you use across multiple tests. They aren’t always as good for tests that require slight variations in the data. They are designed to help you to test your code, not testing your software architecture capability. So don't over engineering the Fixture if the data is not the same for different test case. Just write data inside the test.\n",
    "\n",
    "As with most abstractions, it takes some practice and thought to find the right level of fixture use."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5.3 Fixtures at Scale\n",
    "As you extract more fixtures from your tests, you might see that some fixtures could benefit from further extraction. Fixtures are modular, so they can depend on other fixtures. You may find that fixtures in two separate test modules share a common dependency. What can you do in this case?\n",
    "\n",
    "You can move fixtures from test modules into more general fixture-related modules. That way, you can import them back into any test modules that need them. This is a good approach when you find yourself using a fixture repeatedly throughout your project.\n",
    "\n",
    "**pytest looks for conftest.py modules throughout the directory structure. Each conftest.py provides configuration for the file tree pytest finds it in.** You can use any fixtures that are defined in a particular conftest.py throughout the file’s parent directory and in any subdirectories. This is a great place to put your most widely used fixtures."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5.4 fixtures for guarding access to resources\n",
    "\n",
    "Another interesting use case for fixtures is in guarding access to resources. Imagine that you’ve written a test suite for code that deals with API calls. You want to ensure that the test suite doesn’t make any real network calls, even if a test accidentally executes the real network call code. pytest provides a **monkeypatch fixture** to replace values and behaviors, which you can use to great effect:\n",
    "\n",
    "```python\n",
    "# conftest.py\n",
    "\n",
    "import pytest\n",
    "import requests\n",
    "\n",
    "@pytest.fixture(autouse=True)\n",
    "def disable_network_calls(monkeypatch):\n",
    "    def stunted_get():\n",
    "        raise RuntimeError(\"Network access not allowed during testing!\")\n",
    "    monkeypatch.setattr(requests, \"get\", lambda *args, **kwargs: stunted_get())\n",
    "```\n",
    "\n",
    "\n",
    "By placing **disable_network_calls()** in conftest.py and adding the **autouse=True** option, you ensure that network calls will be disabled in every test across the suite. Any test that executes code calling **requests.get()** will raise a RuntimeError indicating that an unexpected network call would have occurred.\n",
    "\n",
    "You can find the complete example in `src/test_demo/test_with_fixture`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.6 Filtering test\n",
    "\n",
    "As your test suite grows, you may find that you want to run just a few tests on a feature and save the full suite for later. pytest provides a few ways of doing this:\n",
    "\n",
    "- Name-based filtering: You can limit pytest to running only those tests whose fully qualified names match a particular expression. You can do this with the -k parameter.\n",
    "- Directory scoping: By default, pytest will run only those tests that are in or under the current directory.\n",
    "- Test categorization: pytest can include or exclude tests from particular categories that you define. You can do this with the -m parameter.\n",
    "\n",
    "**Test categorization** in particular is a subtly powerful tool. pytest enables you to create marks, or custom labels, for any test you like. A test may have multiple labels, and you can use them for granular control over which tests to run."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.6.1 Marks: Categorizing Tests\n",
    "\n",
    "**Marks enables you to define categories for your tests and provides options for including or excluding categories when you run your suite. You can mark a test with any number of categories.**\n",
    "\n",
    "Let's retake the above two examples, we will add two marks:\n",
    "```python\n",
    "# add this mark to all test in simple test demo\n",
    "@pytest.mark.test_simple\n",
    "\n",
    "# add this mark to all test in fixture demo\n",
    "@pytest.mark.test_fixture\n",
    "```\n",
    "\n",
    "You can run pytest with **-m** option that takes a specific mark. For example below command will only test with mark `@pytest.mark.test_fixture`\n",
    "\n",
    "```shell\n",
    "# go to src folder and run\n",
    "pytest -m test_fixture\n",
    "```\n",
    "\n",
    "You should see below output:\n",
    "\n",
    "``` text\n",
    "===================================================================================================== test session starts =====================================================================================================\n",
    "platform linux -- Python 3.8.10, pytest-5.4.3, py-1.11.0, pluggy-0.13.1\n",
    "rootdir: /home/pliu/git/Learning_Python/learning_python/Lesson01_Basics/Section01_Basic_syntax\n",
    "collected 7 items / 5 deselected / 2 selected\n",
    "\n",
    "src/test_demo/test_with_fixture/test_display.py .                                                                                                                                                                       [ 50%]\n",
    "src/test_demo/test_with_fixture/test_export_csv.py .                                                                                                                                                                    [100%]\n",
    "\n",
    "====================================================================================================== warnings summary =======================================================================================================\n",
    "src/test_demo/simple_test/test_MySum.py:6\n",
    "  /home/pliu/git/Learning_Python/learning_python/Lesson01_Basics/Section01_Basic_syntax/src/test_demo/simple_test/test_MySum.py:6: PytestUnknownMarkWarning: Unknown pytest.mark.test_simple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
    "    @pytest.mark.test_simple\n",
    "\n",
    "src/test_demo/simple_test/test_MySum.py:11\n",
    "  /home/pliu/git/Learning_Python/learning_python/Lesson01_Basics/Section01_Basic_syntax/src/test_demo/simple_test/test_MySum.py:11: PytestUnknownMarkWarning: Unknown pytest.mark.test_simple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
    "    @pytest.mark.test_simple\n",
    "\n",
    "src/test_demo/test_with_fixture/test_display.py:7\n",
    "  /home/pliu/git/Learning_Python/learning_python/Lesson01_Basics/Section01_Basic_syntax/src/test_demo/test_with_fixture/test_display.py:7: PytestUnknownMarkWarning: Unknown pytest.mark.test_fixture - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
    "    @pytest.mark.test_fixture\n",
    "\n",
    "src/test_demo/test_with_fixture/test_export_csv.py:7\n",
    "  /home/pliu/git/Learning_Python/learning_python/Lesson01_Basics/Section01_Basic_syntax/src/test_demo/test_with_fixture/test_export_csv.py:7: PytestUnknownMarkWarning: Unknown pytest.mark.test_fixture - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
    "    @pytest.mark.test_fixture\n",
    "\n",
    "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
    "========================================================================================= 2 passed, 5 deselected, 4 warnings in 0.02s =========================================================================================\n",
    "\n",
    "```\n",
    "\n",
    "Note you have warnings that the marks are not registered. This is a feature that pytest provides\n",
    "\n",
    "Because you can give your marks any name you want, it can be easy to mistype or misremember the name of a mark. pytest will warn you about marks that it doesn’t recognize.\n",
    "\n",
    "The **--strict-markers** flag to the pytest command ensures that all marks in your tests are **registered in your pytest configuration**. It will prevent you from running your tests until you register any unknown marks.\n",
    "\n",
    "You can use this [doc](https://docs.pytest.org/en/latest/how-to/mark.html#registering-marks) to register your marks.\n",
    "\n",
    "You can also combine your test by using **Parametrization**. But we will not talk about this topic here. You can read [this](https://realpython.com/pytest-python-testing/#marks-categorizing-tests) for more details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.7 Durations Reports: Fighting Slow Tests\n",
    "\n",
    "If you want to improve the speed of your tests, then it’s useful to know which tests might offer the biggest improvements. pytest can automatically record test durations for you and report the top offenders.\n",
    "\n",
    "Use the **--durations option** to the pytest command to include a duration report in your test results. **--durations expects an integer value n and will report the slowest n number of tests**. The output will follow your test results:\n",
    "```shell\n",
    "# if the test are quick, you will see nothing, with -vv, it will show you something\n",
    "pytest -m test_fixture --durations=3 -vv\n",
    "```\n",
    "You should see below output\n",
    "```text\n",
    "0.00s setup    test_demo/test_with_fixture/test_display.py::test_format_data_for_display\n",
    "0.00s setup    test_demo/test_with_fixture/test_export_csv.py::test_format_data_for_excel\n",
    "0.00s teardown test_demo/test_with_fixture/test_display.py::test_format_data_for_display\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.8 Useful pytest Plugins\n",
    "\n",
    "### 6.8.1 pytest-randomly\n",
    "pytest-randomly does something seemingly simple but with valuable effect: **It forces your tests to run in a random order**. pytest always collects all the tests it can find before running them, so pytest-randomly shuffles that list of tests just before execution.\n",
    "\n",
    "This is a great way to uncover tests that depend on running in a specific order, which means they have a **stateful dependency** on some other test. If you built your test suite from scratch in pytest, then this isn’t very likely. It’s more likely to happen in test suites that you migrate to pytest.\n",
    "\n",
    "The plugin will print a seed value in the configuration description. You can use that value to run the tests in the same order as you try to fix the issue.\n",
    "\n",
    "### 6.8.2 pytest-cov\n",
    "If you measure how well your tests cover your implementation code, you likely use the coverage package. pytest-cov (https://pytest-cov.readthedocs.io/en/latest/) integrates coverage, so you can run pytest --cov to see the test coverage report.\n",
    "\n",
    "\n",
    "### 6.8.3 pytest-django\n",
    "pytest-django provides a handful of useful fixtures and marks for dealing with Django tests. You saw the django_db mark earlier in this tutorial, and the rf fixture provides direct access to an instance of Django’s RequestFactory. The settings fixture provides a quick way to set or override Django settings. This is a great boost to your Django testing productivity!\n",
    "\n",
    "### 6.8.4 pytest-bdd\n",
    "pytest can be used to run tests that fall outside the traditional scope of unit testing. Behavior-driven development (BDD) encourages writing plain-language descriptions of likely user actions and expectations, which you can then use to determine whether to implement a given feature. pytest-bdd helps you use Gherkin to write feature tests for your code."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}