{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2 Thread\n",
    "\n",
    "In Chapter 1, we have seen how to use Process to accelerate your python program. In this chapter we will see:\n",
    "\n",
    "1. What threads are\n",
    "2. How to create threads and wait for them to finish\n",
    "3. How to use a ThreadPoolExecutor\n",
    "4. How to avoid race conditions\n",
    "5. How to use the common tools that Python threading provide"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 What Is a Python Thread?\n",
    "\n",
    "Generally speaking, a thread is a separate flow of execution, which means that your program will have many flow of execution happening at the same time. But for most Python 3 implementations **the threads do not actually execute at the same time**.\n",
    "\n",
    "This is due to the python interpreter uses [GIL(Global Interpreter Lock)](https://realpython.com/python-gil/) to provide a thread safe memory management environment for the underlying C libraries. And **GIL limits only one Python thread can run at a time**.\n",
    "\n",
    "## 2.2 When to use python thread?\n",
    "\n",
    "As only one python thread can run at a time, if **tasks that spend much of their time waiting for external events are generally good candidates for threading**.\n",
    "\n",
    "If **tasks that require heavy CPU computation and spend little time waiting for external events might not run faster at all after adding multi threading**.\n",
    "\n",
    "**The above condition is true for code written in Python and running on the standard CPython implementation**. If your threads are written in C they have the ability to release the GIL and run concurrently. If you are running on a different Python interpreter implementation, check with the documentation to see how it handles threads.\n",
    "\n",
    "**If you are running a standard Python implementation, writing in only Python, and have a CPU-bound problem, you should check out the multiprocessing module instead.**\n",
    "\n",
    "So Why python still have thread, if they can't run parallely?\n",
    "Thread can provide gains in design clarity for your program architecture. Most of the examples you’ll see in this chapter are not necessarily going to run faster because they use threads. Using threading in them helps to make the design cleaner and easier to reason about."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 A simple thread\n",
    "\n",
    "The Python standard library provides threading, which contains most of the primitives you’ll see in this article. Thread, in this module, nicely encapsulates threads, providing a clean interface to work with them.\n",
    "\n",
    "To start a separate thread, you create a Thread instance and then tell it to .start():\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from threading import Thread"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define a thread task\n",
    "def thread_task(name: str):\n",
    "    logging.info(f\"Thread {name} : start\")\n",
    "    time.sleep(2)\n",
    "    logging.info(f\"Thread {name} : stop\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Main    : before creating thread\n",
      "INFO:root:Main    : before running thread-1\n",
      "INFO:root:Main    : before running thread-2\n",
      "INFO:root:Thread thread-1 : start\n",
      "INFO:root:Thread thread-2 : start\n",
      "INFO:root:Main    : wait for the thread-1 to finish\n",
      "INFO:root:Thread thread-1 : stop\n",
      "INFO:root:Main    : wait for the thread-2 to finish\n",
      "INFO:root:Thread thread-2 : stop\n",
      "INFO:root:Main    : all done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## main process that launches thread\n",
    "# set up logger\n",
    "\n",
    "level=\"INFO\"\n",
    "date_format=\"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(level=level,datefmt=date_format)\n",
    "\n",
    "# start the main process\n",
    "logging.info(\"Main    : before creating thread\")\n",
    "\n",
    "# create thread\n",
    "logging.info(\"Main    : before running thread-1\")\n",
    "thread1=Thread(target=thread_task,args=(\"thread-1\",))\n",
    "logging.info(\"Main    : before running thread-2\")\n",
    "thread2=Thread(target=thread_task,args=(\"thread-2\",))\n",
    "\n",
    "# start thread\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "\n",
    "logging.info(\"Main    : wait for the thread-1 to finish\")\n",
    "thread1.join()\n",
    "\n",
    "logging.info(\"Main    : wait for the thread-2 to finish\")\n",
    "thread2.join()\n",
    "# finish main process\n",
    "logging.info(\"Main    : all done\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above example, when you create a Thread, you pass it **a function and a list containing the arguments to that function**. In our case, you’re telling the Thread to run thread_task() and to pass it `thread-1` as an argument.\n",
    "\n",
    "We recommend you to always give a custom thread name. There is **threading.get_ident()**, which returns a unique name for each thread, but these are usually neither short nor easily readable.\n",
    "\n",
    "\n",
    "### The join() method\n",
    "\n",
    "Try to comment the join(). You will notice the main finish before thread. Run src/SimpleThreadExample.py, it's more clear than the jupyter notebook.\n",
    "So the join() method tells the main process to wait the thread that calls join().\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Daemon Threads\n",
    "\n",
    "**In computer science, a daemon is a process that runs in the background.**\n",
    "\n",
    "**In Python threading, a daemon thread will shut down immediately when the program exits.** As a result, you don't need to worry about shutting the daemon thread down.\n",
    "\n",
    "If a program is running Threads that are not daemons, then the program will wait for those threads to complete before it terminates. Threads that are daemons, however, are just killed wherever they are when the program is exiting.\n",
    "\n",
    "You can create a daemon thread by adding the **daemon=True** flag into the Thread constructor. Check src/DaemonThreadExample.py for example.\n",
    "\n",
    "Run src/DaemonThreadExample.py, you will have below output\n",
    "\n",
    "```text\n",
    "14:24:03: Main    : before creating thread\n",
    "14:24:03: Main    : before running thread-1\n",
    "14:24:03: Main    : before running thread-2\n",
    "14:24:03: Thread thread-1 : start\n",
    "14:24:03: Thread thread-2 : start\n",
    "14:24:03: Main    : wait for the thread-1 to finish\n",
    "14:24:03: Main    : wait for the thread-2 to finish\n",
    "14:24:03: Main    : all done\n",
    "```\n",
    "\n",
    "You can notice the two thread are started, by never finished. Because the main process finish before thread task, as the thread are daemon thread. They are automatically shut down after the main terminates. If you add the join, then the thread can finish normally."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Working with many threads\n",
    "\n",
    "Similar to Process, when you have many Thread to create and stop, you need to use a **ThreadPoolExecutor, and it’s part of the standard library in concurrent.futures (as of Python 3.2)**. Otherwise, the thread context creation may take much more time than your task.\n",
    "\n",
    "The ThreadPoolExecutor has three principal functions:\n",
    "- submit(): Dispatch a function to be executed and return a future object.\n",
    "- map(): Apply a function to an iterable of elements.\n",
    "- shutdown(): Shut down the executor.\n",
    "\n",
    "Below figure shows the life cycle of a thread pool executor\n",
    "\n",
    "![python_thread_pool_life_cycle.PNG](../../images/python_thread_pool_life_cycle.PNG)\n",
    "### Future object\n",
    "\n",
    "A future is an object that **represents a delayed result for an asynchronous task**.\n",
    "\n",
    "It is also sometimes called a `promise` or a `delay`. It provides a context for the result of a task that may or may not be executing and a way of getting a result once it is available.\n",
    "\n",
    "In Python, the Future object is returned from an Executor, such as a ThreadPoolExecutor when calling the submit() function to dispatch a task to be executed asynchronously.\n",
    "\n",
    "In general, we do not create Future objects; we only receive them and we may need to call functions on them.\n",
    "\n",
    "The Future object provides a number of helpful functions for inspecting the status of the task such as: **cancelled(), running(), and done()** to determine if the task was cancelled, is currently running, or has finished execution.\n",
    "\n",
    "- cancelled(): Returns True if the task was cancelled before being executed.\n",
    "- running(): Returns True if the task is currently running.\n",
    "- done(): Returns True if the task has completed or was cancelled.\n",
    "\n",
    "### Simple thread pool executor example\n",
    "\n",
    "The easiest way to create it is as a context manager, using the **with** statement to manage the creation and destruction of the pool. Once we have the executor, we can submit tasks to the pool via two below methods:\n",
    "- map:\n",
    "- submit:\n",
    "\n",
    "Check src/ThreadPoolExample.py for a detailed example\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5 Race condition\n",
    "\n",
    "**Race conditions can occur when two or more threads access a shared piece of data or resource.** Frequently, they only occur rarely, and they can produce confusing results. As you can imagine, this makes them quite difficult to debug.\n",
    "\n",
    "Check **src/RaceConditionExample.py**, and run it. You will find below output:\n",
    "```text\n",
    "18:49:51: Testing update. Starting value is 0.\n",
    "18:49:51: Thread 0: starting update\n",
    "18:49:51: Thread 0 has init db value 0\n",
    "18:49:51: Thread 1: starting update\n",
    "18:49:51: Thread 1 has init db value 0\n",
    "18:49:51: Thread 1 output value 1 to db\n",
    "18:49:51: Thread 1: finishing update\n",
    "18:49:51: Thread 0 output value 1 to db\n",
    "18:49:51: Thread 0: finishing update\n",
    "18:49:51: Testing update. Ending value is 1.\n",
    "```\n",
    "\n",
    "Surprise, the ending value in database is not 2. Because thread 1, thread 2 start at same time, they both read init value 0. After calculation, they both have 1 as result. Then they both write to db with value 1. The order who writes first to db is not determined, but we know the latter will overwrite the former, not increment the result of the former. This is a typical **race condition**. Instead of coordinate the result between threads, thread overwrites the result of each other."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.6 Basic Synchronization Using Lock\n",
    "\n",
    "The easiest way to solve race conditions is to use a **Lock**, which allows only one thread at a time to access the read-modify-write shared resources (can be data or code).\n",
    "\n",
    "Check **src/LockExample.py**, we use a lock to protect the reading and writing of the fake database. It means if a thread is access the database, other thread can't access the database.\n",
    "\n",
    "Run it, you will have below output:\n",
    "\n",
    "```text\n",
    "19:18:50: Testing update. Starting value is 0.\n",
    "19:18:50: Thread 0: starting update\n",
    "19:18:50: Thread 0 acquired lock\n",
    "19:18:50: Thread 0 has init db value 0\n",
    "19:18:50: Thread 1: starting update\n",
    "19:18:50: Thread 0 released lock\n",
    "19:18:50: Thread 0 output value 1 to db \n",
    "19:18:50: Thread 0: finishing update\n",
    "19:18:50: Thread 1 acquired lock\n",
    "19:18:50: Thread 1 has init db value 1\n",
    "19:18:50: Thread 1 released lock\n",
    "19:18:50: Thread 1 output value 2 to db \n",
    "19:18:50: Thread 1: finishing update\n",
    "19:18:50: Testing update. Ending value is 2.\n",
    "```\n",
    "\n",
    "You can notice the output is correct this time."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}